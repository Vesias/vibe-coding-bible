import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/lib/supabase/server'

export async function POST(request: NextRequest) {
  try {
    const { audioData, personality, language } = await request.json()
    
    // Get authenticated user
    const supabase = await createClient()
    const { data: { user } } = await supabase.auth.getUser()
    
    if (!user) {
      return NextResponse.json(
        { error: 'Authentication required for voice chat' },
        { status: 401 }
      )
    }
    
    // Validate input
    if (!audioData) {
      return NextResponse.json(
        { error: 'Audio data is required' },
        { status: 400 }
      )
    }
    
    // For now, return a mock response
    // In production, this would integrate with speech-to-text and text-to-speech APIs
    const mockResponse = {
      transcription: "Hallo, ich brauche Hilfe mit React Hooks.",
      response: {
        text: `üéôÔ∏è **${personality || 'Moses the Code Giver'} spricht:**\n\nAh, ein Suchender der React-Weisheit! Hooks sind wie heilige Werkzeuge - sie verbinden deine Komponenten mit dem g√∂ttlichen Zustand des Universums. Lass mich dir die Geheimnisse der useState und useEffect offenbaren...`,
        audioUrl: '/api/ai/voice-chat/audio/response-123.mp3', // Mock audio URL
        personality: personality || 'Moses the Code Giver',
        duration: 45000, // Mock duration in ms
        suggestions: [
          'Erkl√§re mir useState genauer',
          'Wie funktioniert useEffect?',
          'Zeige mir ein Beispiel',
          'Was sind die besten Practices?'
        ]
      }
    }
    
    // Log voice interaction
    try {
      await supabase
        .from('ai_voice_interactions')
        .insert({
          user_id: user.id,
          personality: personality || 'Moses the Code Giver',
          language: language || 'deutsch',
          transcription_length: mockResponse.transcription.length,
          response_duration: mockResponse.response.duration,
          audio_quality: 'high'
        })
    } catch (error) {
      console.warn('Failed to log voice interaction:', error)
    }
    
    return NextResponse.json(mockResponse)
    
  } catch (error) {
    console.error('Voice Chat API Error:', error)
    
    return NextResponse.json(
      { 
        error: 'Failed to process voice chat',
        message: error instanceof Error ? error.message : 'Unknown error'
      },
      { status: 500 }
    )
  }
}

export async function GET() {
  return NextResponse.json({
    status: 'Voice Chat API is running',
    features: [
      'Speech-to-text transcription',
      'AI response generation',
      'Text-to-speech synthesis',
      'Multiple personality voices',
      'Multi-language support'
    ],
    supportedLanguages: ['deutsch', 'english'],
    maxAudioDuration: 60000, // 60 seconds
    audioFormats: ['wav', 'mp3', 'webm']
  })
}